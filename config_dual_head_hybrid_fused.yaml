# Configuration for Hybrid+Fused Dual-Head ViTA-Seg Model
# Shared early decoder + task-specific late decoder + fusion architecture

model:
  img_size: 224
  patch_size: 16
  in_channels: 4  # RGB image (3) + visible mask (1)
  embed_dim: 768
  depth: 12
  num_heads: 12
  mlp_ratio: 4
  dropout: 0.1
  shared_channels: [512, 256]  # Early shared layers: 768→512→256
  task_specific_channels: [128, 64]  # Late task-specific layers: 256→128→64
  pretrained_model: "vit_base_patch16_224.mae"  # Use MAE pretrained ViT
  freeze_backbone: False
  freeze_pretrained: False

data:
  datasets: "kins"  # Options: 'vitasim', 'cocoa', 'kins', 'both', 'all'
  target_size: [224, 224]
  
  vitasim:
    root_dir: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/ViTASimDataArol"
    train_annotations: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/ViTASimDataArol/ViTASim_amodal_train2014_with_classes.json"
    val_annotations: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/ViTASimDataArol/ViTASim_amodal_val2014_with_classes.json"
    train_fusion: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/ViTASimDataArol/fusion_train.pkl"
    val_fusion: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/ViTASimDataArol/fusion_test.pkl"
  
  cocoa:
    root_dir: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/COCOA"
    train_annotations: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/COCOA/COCO_amodal_train2014_with_classes.json"
    val_annotations: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/COCOA/COCO_amodal_val2014_with_classes.json"
  
  kins:
    root_dir: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/KINS"
    train_annotations: "update_train_2020.json"
    val_annotations: "update_test_2020.json"
    train_fusion: "fusion_train_kins.pkl"
    val_fusion: "fusion_test_kins.pkl"
    enlarge_coef: 2.0
  
  d2sa:
    root_dir: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/D2SA"
    train_annotations: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/D2SA/D2S_amodal_augmented.json"
    val_annotations: "C:/Users/Proprietario/Desktop/Donato/python_project/c2f-seg/data/D2SA/D2S_amodal_validation.json"

training:
  epochs: 100
  batch_size: 8
  num_workers: 0
  learning_rate: 5.0e-6
  min_lr: 1.0e-8
  weight_decay: 0.01
  gradient_clip_norm: 0.1
  gradient_accumulation_steps: 2
  seed: 42
  
  # Loss weights for hybrid+fused dual-head model
  loss_weights:
    amodal: 1.0
    occluded: 0.25
    dice: 1.0 
    bce: 1.0
  
  optimizer:
    type: "adamw"
    beta1: 0.9
    beta2: 0.999
    eps: 1.0e-8
  
  scheduler:
    type: "warmup_linear"
    warmup_iters: 1000
  
  mixed_precision: false

# WandB configuration
wandb:
  project: "vita-seg-dual-head-hybrid-fused"
  entity: null
  notes: "Hybrid+Fused decoder: shared early (768→512→256) + task-specific late (256→128→64) + fusion"
