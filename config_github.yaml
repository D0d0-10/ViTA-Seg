# Configuration for Hybrid+Fused Dual-Head ViTA-Seg Model
# Shared early decoder + task-specific late decoder + fusion architecture

model:
  img_size: 224
  patch_size: 16
  in_channels: 4  # RGB image (3) + visible mask (1)
  embed_dim: 768
  depth: 12
  num_heads: 12
  mlp_ratio: 4
  dropout: 0.1
  shared_channels: [512, 256]  # Early shared layers: 768→512→256
  task_specific_channels: [128, 64]  # Late task-specific layers: 256→128→64
  pretrained_model: "vit_base_patch16_224.mae"  # Use MAE pretrained ViT
  freeze_backbone: False
  freeze_pretrained: False

data:
  datasets: "vitasim"  # Options: 'vitasim', 'cocoa', 'kins', 'both', 'all'
  target_size: [224, 224]
  
  vitasim:
    root_dir: "./data/ViTASim"
    train_annotations: "./data/ViTASim/ViTASim_amodal_train2014_with_classes.json"
    val_annotations: "./data/ViTASim/ViTASim_amodal_val2014_with_classes.json"
    train_fusion: "./data/ViTASim/fusion_train.pkl"
    val_fusion: "./data/ViTASim/fusion_test.pkl"
  
  cocoa:
    root_dir: "./data/COCOA"
    train_annotations: "./data/COCOA/COCO_amodal_train2014_with_classes.json"
    val_annotations: "./data/COCOA/COCO_amodal_val2014_with_classes.json"
  
  kins:
    root_dir: "./data/KINS"
    train_annotations: "update_train_2020.json"
    val_annotations: "update_test_2020.json"
    train_fusion: "fusion_train_kins.pkl"
    val_fusion: "fusion_test_kins.pkl"
    enlarge_coef: 2.0

training:
  epochs: 100
  batch_size: 8
  num_workers: 0
  learning_rate: 5.0e-6
  min_lr: 1.0e-8
  weight_decay: 0.01
  gradient_clip_norm: 0.1
  gradient_accumulation_steps: 2
  seed: 42
  
  # Loss weights for hybrid+fused dual-head model
  loss_weights:
    amodal: 1.0
    occluded: 0.25  # Adjust between 0.25-0.50 based on dataset
    dice: 1.0 
    bce: 1.0
  
  optimizer:
    type: "adamw"
    beta1: 0.9
    beta2: 0.999
    eps: 1.0e-8
  
  scheduler:
    type: "warmup_linear"
    warmup_iters: 1000
  
  mixed_precision: false

# WandB configuration
wandb:
  project: "vita-seg-dual-head-hybrid-fused"
  entity: null  # Set to your WandB username or team
  notes: "Hybrid+Fused decoder: shared early (768→512→256) + task-specific late (256→128→64) + fusion"
